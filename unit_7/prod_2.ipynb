{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим модель линейной регрессии на встроенном датасете Diabetes dataset.\n",
    "# Опустим кросс-валидацию и разделение выборки на обучение и тест, так как для наших целей это не важно.\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    }
   ],
   "source": [
    "# Импортируем модуль и воспользуемся методом dumps:\n",
    "model = pickle.dumps(regressor)\n",
    "print(type(model))\n",
    "print(type(regressor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Восстановим объект Python:\n",
    "regressor_from_bytes = pickle.loads(model)\n",
    "regressor_from_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним объект прямо в файл:\n",
    "with open(\"./prod_2.pkl\", \"wb\") as output:\n",
    "    pickle.dump(regressor, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Файл prod_1.pkl так же легко десериализовать:\n",
    "with open(\"./prod_2.pkl\", \"rb\") as pkl_file:\n",
    "    regressor_from_file = pickle.load(pkl_file)\n",
    "\n",
    "regressor_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Убедимся, что методы и результаты предсказаний обученной модели и загруженной из файла совпадают:\n",
    "print(all(regressor.predict(X) == regressor_from_bytes.predict(X)))\n",
    "print(all(regressor.predict(X) == regressor_from_file.predict(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"Scaling\", MinMaxScaler()),\n",
    "        (\"FeatureSelection\", SelectKBest(f_regression, k=5)),\n",
    "        (\"Linear\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipe.fit(X, y)\n",
    "pipe.predict(X[1:2])\n",
    "s1 = pickle.dumps(pipe)\n",
    "pipe_from_bytes = pickle.loads(s1)\n",
    "\n",
    "print(all(pipe.predict(X) == pipe_from_bytes.predict(X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что для работы с файлами используются методы pickle.dump и pickle.load, а для работы с сериализованными объектами pickle.dumps и pickle.loads.\n",
    "\n",
    "Как мы видим, Pickle прекрасно справляется со своей задачей, однако иногда массивы данных бывают настолько большими, что после загрузки из Pickle можно не восстановить объект полностью. \n",
    "\n",
    "В таких случаях лучше использовать Joblib вместо Pickle. Этот модуль более эффективен для объектов, которые содержат большие массивы данных. Он оптимизирован для быстрой и надежной работы с данными большого объема. Пожалуй, единственный минус этого модуля в том, что он может «консервировать» только в файл, поэтому вы не сможете получить объект в виде бинарной строки и работать с ним. В модуле попросту отсутствуют методы для работы с бинарной строкой.\n",
    "\n",
    "Для иллюстрации работы сохраним обученную модель:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "dump(regressor, \"prod_2.joblib\")\n",
    "\n",
    "clf_from_jobliv = load(\"prod_2.joblib\")\n",
    "all(regressor.predict(X) == clf_from_jobliv.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллега обучил модель и теперь просит вас проверить её на ваших данных. Он присылает вам Pickle-файл. Загрузите модель, используя модуль Pickle. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret word: skillfactory\n",
      "how is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexigna/projects/skillfactory/data science/skillfactory_rds/venv/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 0.22.2.post1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"hw1.pkl\", \"rb\") as hw_file:\n",
    "    model = pickle.load(hw_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.666])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([1, 1, 1, 0.661212487096872])\n",
    "y_pred = model.predict(X_test.reshape(1, -1))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# У модели есть два поля с именами a и b. Создайте из них словарь с такими же\n",
    "# именами ключей и значениями, а затем сохраните в файл с помощью модуля Pickle. \n",
    "dict_to_file = {\n",
    "    \"a\": model.a,\n",
    "    \"b\": model.b,\n",
    "}\n",
    "with open(\"prod_2.8.4.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump(dict_to_file, pickle_file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyoka import skl_to_pmml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "cols = load_diabetes()[\"feature_names\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"Scaling\", MinMaxScaler()),\n",
    "        (\"Linear\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "# Тренировка пайплайна, включающего линейную модель и нормализацию признаков\n",
    "pipe.fit(X, y)\n",
    "# Сохраним пайплайн в формате pmml в файл pipe.pmml\n",
    "skl_to_pmml(pipeline=pipe, col_names=cols, pmml_f_name=\"prod_2.9.pipe.pmml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "\n",
    "# загружаем данные\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# обучаем модель\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# делаем инференс моделью на тесте\n",
    "test_pred = model.predict(X_test)\n",
    "print('sklearn model predict:\\n', test_pred)\n",
    "\n",
    "# конвертируем модель в onnx формат\n",
    "initial_type = [('float_input', FloatTensorType([None, 13]))]\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# сохраняем модель в файл\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "\tf.write(model_onnx.SerializeToString())\n",
    " \t \n",
    "# Делаем инференс на тесте через onnxruntime\n",
    "sess = rt.InferenceSession(\"model.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "test_pred_onnx = sess.run([label_name],\n",
    "                \t{input_name:  X_test.astype(np.float32)})[0].reshape(-1)\n",
    "print('onnx model predict:\\n',test_pred_onnx) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "550056ff3b6c24ef08b20d0608428d73c2737dc12cdd6267fe4ea38c5eab2d02"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
